---
---

@inproceedings{kausik2023learning, 
title={Learning mixtures of Markov chains and MDPs}, 
author={Kausik, Chinmaya and Tan, Kevin and Tewari, Ambuj}, 
booktitle={International Conference on Machine Learning}, 
pages={15970--16017}, year={2023}, 
organization={PMLR},
url={https://proceedings.mlr.press/v202/kausik23a.html},
abstract = {We present an algorithm for learning mixtures of Markov chains and Markov decision processes (MDPs) from short unlabeled trajectories. Specifically, our method handles mixtures of Markov chains with optional control input by going through a multi-step process, involving (1) a subspace estimation step, (2) spectral clustering of trajectories using "pairwise distance estimators," along with refinement using the EM algorithm, (3) a model estimation step, and (4) a classification step for predicting labels of new trajectories. We provide end-to-end performance guarantees, where we only explicitly require the length of trajectories to be linear in the number of states and the number of trajectories to be linear in a mixing time parameter. Experimental results support these guarantees, where we attain 96.6% average accuracy on a mixture of two MDPs in gridworld, outperforming the EM algorithm with random initialization (73.2% average accuracy). We also significantly outperform the EM algorithm on real data from the LastFM song dataset.}
}


@inproceedings{kausik2024offline,
  title={Offline policy evaluation and optimization under confounding},
  author={Kausik, Chinmaya and Lu, Yangyi and Tan, Kevin and Makar, Maggie and Wang, Yixin and Tewari, Ambuj},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1459--1467},
  year={2024},
  organization={PMLR},
  url={https://proceedings.mlr.press/v238/kausik24a.html},
  abstract={Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on whether they are memoryless and on their effect on the data-collection policies. We characterize settings where consistent value estimates are provably not achievable, and provide algorithms with guarantees to instead estimate lower bounds on the value. When consistent estimates are achievable, we provide algorithms for value estimation with sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on both a gridworld environment and a simulated healthcare setting of managing sepsis patients. In gridworld, our model-based method provides tighter lower bounds than existing methods, while in the sepsis simulator, we demonstrate the effectiveness of our method and investigate the importance of a clustering sub-routine.}
}

@article{
kausik2024double,
title={Double Descent and Overfitting under Noisy Inputs and Distribution Shift for Linear Denoisers},
author={Chinmaya Kausik and Kashvi Srivastava and Rishi Sonthalia},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=HxfqTdLIRF},
note={},
abstracts={Despite the importance of denoising in modern machine learning and ample empirical work on supervised denoising, its theoretical understanding is still relatively scarce. One concern about studying supervised denoising is that one might not always have noiseless training data from the test distribution. It is more reasonable to have access to noiseless training data from a different dataset than the test dataset. Motivated by this, we study supervised denoising and noisy-input regression under distribution shift. We add three considerations to increase the applicability of our theoretical insights to real-life data and modern machine learning. First, while most past theoretical work assumes that the data covariance matrix is full-rank and well-conditioned, empirical studies have shown that real-life data is approximately low-rank. Thus, we assume that our data matrices are low-rank. Second, we drop independence assumptions on our data. Third, the rise in computational power and dimensionality of data have made it important to study non-classical regimes of learning. Thus, we work in the non-classical proportional regime, where data dimension $d$ and number of samples $N$ grow as $d/N =  c + o(1)$. 

For this setting, we derive data-dependent, instance specific expressions for the test error for both denoising and noisy-input regression, and study when overfitting the noise is benign, tempered or catastrophic. We show that the test error exhibits double descent under general distribution shift, providing insights for data augmentation and the role of noise as an implicit regularizer. We also perform experiments using real-life data, where we match the theoretical predictions with under 1\% MSE error for low-rank data.}
}

@article{friedl2022algorithm,
  title={An algorithm to calculate generalized Seifert matrices},
  author={Friedl, Stefan and Kausik, Chinmaya and Quintanilha, Jos{\'e} Pedro},
  journal={Journal of Knot Theory and Its Ramifications},
  volume={31},
  number={11},
  pages={2250068},
  year={2022},
  publisher={World Scientific},
  url={https://arxiv.org/abs/2204.10004}
}
